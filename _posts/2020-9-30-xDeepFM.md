---
layout:     post
title:      "xDeepFM-eXtreme Deep Factorization Machine"
subtitle:   "论文阅读笔记"
date:       2020-9-30 12:00:00
author:     "baiyf"
header-img: "img/about-bg-walle.jpg"
header-mask: 0.3
catalog:    true
tags:
    - Papers


---

# xDeepFM

## 背景与动机

- 交叉特征非常重要
- 传统交叉特征提取方式需要大量人力，可以改进
- 认为DCN的特征组合方式存在缺陷
  - cross网络是限定在一种特殊形式下实现高阶交叉特征的，即cross网络中每一层输出都是$$x_0$$的标量乘积：$$a^ix_0$$
  - cross网络是以bit-wise形式交叉的，即便是同一个field embedding向量下的元素也会相互影响

## 贡献点

- 提出新的xDeepFM模型结构，同时**显式的和隐式的**学习高阶特征组合
- 提出**CIN**结构显式的学习高阶特征组合，特征vector-wise的交互而非bit-wise的

#### CIN

针对DCN中cross部分的不足，xDeepFM提出了新的解决方法，CIN

![CIN模块](/img/post/xDeepFM/CIN模块.png)

作者认为CIN有以下几个优点：

- a.**vector-wise的获得组合特征**，而非bit-wise；
- b.可以**显式地获得高阶特征组合**；
- c.**网络复杂度**不会随组合阶数指数级增长

CIN计算的数学形式为：

![CIN公式](/img/post/xDeepFM/CIN公式.png)

W代表参数矩阵，右半边代表两个向量的哈达玛积（即elementwise积），如果用T表示网络深度，那么CIN最高可以实现T+1阶的特征交叉。

输出：最终输出$$p+$$是每层$$x^k$$沿embedding维度sum pooling后再拼接的向量：

<img src="/img/post/xDeepFM/p+.png" alt="p+" style="zoom:33%;" />

其中$$p^k=[p_1^k, p_2^k, ..., p_{H_k}^k], H_k代表特征图数$$

$$p_i^k=\sum_{j=1}^DX_{i,j}^k$$

![CIN 3D](/img/post/xDeepFM/CIN 3D.png)

CIN的3D表示如上图所示，CIN（*Compressed Interaction Network*）中的Compressed体现在用kernel对$$Z^k$$的加权和

#### 整体架构

Linear、CIN、DNN三部分的组合

组合公式为：

<img src="/img/post/xDeepFM/xDeepFM前向公式.png" alt="模型整体输出" style="zoom:50%;" />

模型结构为：

![模型架构](/img/post/xDeepFM/xDeepFM整体架构.png)

- 与FM/DeepFM的关系：

  - 当depth和feature maps都被设置为1时，xDeepFM就退化为了DeepFM
  - 当继续移除DNN部分，同时对feature map使用sum filter，xDeepFM就退化为普通的FM模型

  

## 实验效果

- 单结构性能对比（CIN）：

  <img src="/img/post/xDeepFM/单结构性能对比.png" alt="单结构性能对比" style="zoom:67%;" />

- 整模型性能对比：

![整模型性能对比](/img/post/xDeepFM/整模型性能对比.png)