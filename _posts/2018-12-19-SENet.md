---
layout:     post
title:      "Squeeze-and-Excitation Networks"
subtitle:   "论文阅读笔记"
date:       2018-12-19 13:00:00
author:     "baiyf"
header-img: "img/about-bg-walle.jpg"
header-mask: 0.3
catalog:    true
tags:
    - Papers


---

# Squeeze-and-Excitation Networks

## 写在前面

本文发表在CVPR-2017上，Momenta基于本文模型的融合模型赢得了ImageNet最后一届比赛(ImageNet2017)的图像识别冠军

## 主要思想

作者的Motivation是显式地建模特征通道之间的相互依赖关系。并且在不引入新的空间维度来进行特征通道间融合的前提下，采用了一种全新的**特征重标定**策略，通过学习的方式自动获取到每个特征通道的重要程度，然后根据这个重要程度去提升有用的特征并抑制对当前任务用处不大的特征

**Squeeze-and-Excitation(SE):**

![SE_module](/img/post/SE_module.jpg)

- Squeeze: 首先是Squeeze操作，沿着空间维度对输入进行特征压缩，使每个二维的特征通道变成一个实数，这个实数在某种程度上具有全局的感知野。这是一个输出维度与输入特征通道数相匹配的向量，表征着在特征通道上相应的全局分布

- Excitation: 其次是Excition操作，它类似于一个门操作，通过参数W来为每个通道生成权重，参数w被用来显式地建模特征通道之间的相关性

- 最后是Rewight操作，把Excitation输出的权重通过按位乘法加到之前的特征通道上，完成通道维度上对原始特征的重标定

## 网络模型

SE这种思想可以应用在很多state-of-art网络模型上，例如ResNet, ResNeXt, MobileNet, ShuffleNet等, 这里以ResNet和Inception为例：

![SEInception](/img/post/SEInception.png)![SEResNet](/img/post/SEResNet.png)

## 实验结论

SENet会略微增加模型的参数量和计算复杂度，但会显著提升基本模型的性能，但作者也提到了本文大量使用的Global average pooling和FC在现有GPU库函数中都还有优化的空间。以ResNet为例：

![SENet-complexity](/img/post/SENet-complexity.png)

## 开源代码

作者开源了Caffe代码：[SENet](https://github.com/hujie-frank/SENet)

## 参考文献

1. [Squeeze-and-Excitation Networks](https://arxiv.org/pdf/1709.01507.pdf)
2. [Momenta详解ImageNet 2017夺冠架构SENet](https://baijiahao.baidu.com/s?id=1574593150997120&wfr=spider&for=pc)